package lessons.week9;

import bitmap.BitMap;

import java.nio.charset.StandardCharsets;
import java.security.MessageDigest;
import java.security.NoSuchAlgorithmException;
import java.util.BitSet;

/**
 * @version 1.0
 * @Description: 海量数据处理
 * @author: bingyu
 * @date: 2023/3/1
 */
public class MassiveDataProcessing {


    /*
     一、海量数据处理面对两个问题:
        1.一台机器的内存存不下
        2.一台机器处理起来太慢

     二、海量数据处理的核心思想: 分治
        单机: 利用外存，分批加入内存处理
        多机: 对数据分片，利用多机内存存储
        多机: 并行计算，利用多线程、多机并行处理

     三、一些处理技巧
        1.外部排序:多路归并、桶排序
        2.哈希分片
        3.位图

     四、常见的问题：
        1.海量数据排序
        2.海量数据查询
        3.海量数据TOP K
        4.海量数据求频率TOP K
        5.海量数据去重/找重
        6.两个海量数据文件找重

     五、具体题目。
       1.按照金额大小给10GB的订单文件进行排序(假设内存不够10GB) ----海量数据排序问题

       TODO:  思路1: 使用"分治，再多路归并"的思想，类似归并排序的处理思路,先将10GB的文件依次取1GB数据到内存里进行排序，生成的文件放入外存，得到 0.txt、1.txt、2.txt.......9.txt
                这10个排好序的1GB文件，然后我们申请长度为10的数组，我们每次从每个文件里面顺序的读取一个数据出来放到数组里面，然后从中取出最小的数据
                min放入结果文件result.txt里，假设该min数据来自1.txt文件，那么我们需要继续顺序读取1.txt文件里的数据，来顶替之前min空出来的位置,
                再取数组中的最小值放入结果文件result.txt里，依次循环执行直到所有文件的处境全部处理完，那么得到的结果文件result.txt就是最终排好序
                的10GB文件了!因为每个小文件都是已经排好序的，第一次从10个小文件中读取数据比较出来得到的最小值就是所有数据中的最小值了！要注意的是
                我们每次从外存的每个文件里面只读一个数据的IO操作是很慢的，因此我们在每个文件弄个100MB前置缓存，取的时候从这个前置缓存中取数据就很快了。

       TODO:   思路2: 使用"桶排序"，10GB的数据假设是订单数据，这些订单金额的范围是0~1000，我们将0~99的金额范围放到0.txt文件，
               100~199放到1.txt文件.....900~999放到9.txt文件里，如果订单分部均匀的话，每个文件大小就是1GB,然后再将每个文件里的数据进行排序
               ，现在文件里数据是排好序的，10个文件之间也是排好序的，这样就可以顺序合并成一个有序的大文件了。
              注意:如果数据分布均与，而且数据不是很大是可以用桶排序的，如果分布不均匀就只能使用多路归并的思路，因此可以看出，分治，然后多路归并才是
              更加普适的。



       2.有一个ip地址白名单文件，包含10亿个IP地址，判断某IP是否在白名单中?(海量数据查询问题)
        补充知识:  ip地址由4个byte(字节)组成，是一个32bit(位)的二进制数，字节这个词专门用来表示8位的二进制数，作为一个8位二进制数，一个字节可以
                 从00000000取值到11111111。这些数可以代表0~255的正数，也可以表示-128~127范围之内的正、负数，而ip需要4个这样的数，
                  因此是4个字节!

        TODO: 由于一个ip地址是由4个字节组成，那么10亿个ip地址相当于4 * 10^3 * 10^3 * 10^3 = 4GB，相当于4GB的数据,如果有4GB的内存，
              我们可以直接构建哈希表，直接查询解决，但是如果我们只有1GB内存。我们就要用到位图!如果用一位来表示一个ip地址是否存在，那么
              10亿个ip我们只需要10^9位，10^9bit/8=1,000,000,000=125,000,000字节
              125,000,000字节/1024=122070KB  122070KB/1024=119MB，也就是说只需要119MB就能构成一个10亿ip的位图。
              xxx.xxx.xxx.xxx ip每个分段是0~255范围的数字，即每个分段有256种可能，所有不同的ip总数就是256^4次方，也就是42亿个，
              如果用位图表示，那么需要42亿个位，也就是相当于500MB即可包含所有的ip是否存在。
              那么问题来了，我们如何将那么多ip和位图的每一位一一对应起来呢?
               其实位图就是一个特殊的散列表，将所有ip均匀的分布到位图的每一位，其实就是对ip地址进行散列，那么重点就是这个散列算法了。
               0.0.0.0~255.255.255.255，很明显这不能用作单纯的数字进行hash，
               我们使用long[]，1个元素就有64位，42亿除以64等于65625000，约需要6562万长度的long数组，因此我们首先将ip转换成数字，然后对每个ip
               进行MD5哈希

        */

    public static void main(String[] args) throws NoSuchAlgorithmException {
        /*
        TODO:位图复习
        0xffffffffffffffffL 说明是16进制，因为f是16进制，相当于10进制的16，也就是相当于2进制的1111，因此1个f代表4个2进制1,
        所以，这里有16个f说明是64个1; long占8个字节，1个字节等于8位，因此一共是64位bitmap中 "int wordIndex = wordIndex(bitIndex);"
        这个方法是将bitIndex >> 0xffffffffffffffffL，其实就是除以64，得到在数组中的哪一个分段，即要存到哪一个数组元素中，然后再到那个
        数组元素中的第5个比特位设置1即可

         */
        //java官方实现的位图，但是这个是直接将其放入位图的位置，还是无法将实际数据和位图的位置联系起来，用的long数组作为位图
//        BitSet bitSet = new BitSet(); //传的是你最终要存入的数据个数。
//        boolean exist = bitSet.get(5);
//        System.out.println(exist);
//        bitSet.set(5); //在第5位设置
//        exist = bitSet.get(5);
//        System.out.println(exist);
//        System.out.println("16进制: "+ 0xffffffffffffffffL); //输出-1

        /*
         MD5Byte数组转16进制
         */
        byte[] bytes = "hello".getBytes(StandardCharsets.UTF_8);
        MessageDigest md = MessageDigest.getInstance("MD5");
        //MD5生成了一个长度为16的字节数组，因为每个字节(byte)有 8 个位(bit), 所以最终的输出值是一个16 × 8 = 128 位的二进制数. MD5 的值
        // 就是一个128位的二进制大整数。
        byte[] md5Hash = md.digest(bytes);
        String s = byte2Hex(md5Hash); //将字节数组转为16进制
        System.out.println(s);

        //测试字节数组转16进制中0x100的作用
        byte[] ba = new byte[256];
        for (int i = -128; i <= 127; i++) {
            ba[i+128]=(byte)i;
            System.out.println(ba[i+128]);
        }
        for (int i = 0; i <=255; i++) {
            System.out.print(Integer.toString(ba[i] & 0xff,16)+"  "); //发现这样0~f只输出了1位，因此为了输出2个字符，需要加上0x100
            System.out.println(Integer.toString((ba[i] & 0xff) + 0x100,16));
        }
    }



    /*
       3.10亿个整数，判断某个整数是否在其中?(同第2题一样的处理思路)

       4.10亿个整数，放在文件中，内存有限，如何求最大的TOP100个整数?(就是找前100大的元素)
         TODO: 在内存里先构建一个小顶堆，然后顺序从10亿整数文件里读取数据，如果堆里的数据还没超过100，就直接把读取的数据插入堆中，如果超过了，
          就和堆顶元素进行比较，如果比堆顶元素大，就把堆顶元素删掉，把新的数据插进去；如果比堆顶元素小就不做处理,这样所有元素都处理完后，这个堆里
          存储的就是前100大的元素了(具体到细节时，可以先从硬盘读取200M的数据到内存，然后在内存中进行上述的堆排序即可，这样减少IO操作)

       5.100GB的搜索关键字文件，统计出现频率TOP前100的关键词
         TODO: 首先统计出所有词汇的频率，然后就简单了，用堆来求top100即可，那么这个难点就是如何统计所有词的频率?
          方法1: 先排序，这样相同的词，就会排在一起了，如果使用排序，由于数据是100G，变成了海量数据排序的问题，相当于第1个问题了，解决了
          海量数据排序的问题后，我们得到的就是一个有序的100GB的数据，然后我们再依次扫描这些100GB的数据统计出词汇和出现频率的次数<word,count>，并
          写到新的文件中(每次写入个200MB)，当有了这个word和对应频率的文件后，剩下的就是解决海量数据TOPK的问题了。相当于第2个问题了。
          方法2: 使用哈希表统计出词汇和其频率，问题是我们不可能构建出那么大的哈希表，因此我们可以进行hash分片，使用多机来解决，假设内存12GB,
          100G,分10批放进10G内存，哈希分片 md5(word)%10 = 0 ~ 9,把结果为0的拉到内存中用哈希表统计每个单次出现的频率,写到一个小文件中;
          接着顺序读取后面的数据，读取10G放入内存，再进行哈希分片，把结果为1的放进内存，并统计出现频率，然后同样写到一个小文件中，就这样依次执行，
          直到得到了10个10GB的小文件,这些小文件都存储了word及其对应的频率，然后将其合并为一个大文件再求TOP100！
          (补充知识: MD5得到的实际是一个长度16的字节数组，我们平常看到生成的MD5字符串实际是由这个字节数组转换成16进制得到的!因为MD5是一个哈希算法，
           其离散非常随机，因此可以作为哈希函数来进行分片)

       6.一个文件中包含10亿条URL，有可能会重复，将重复的去掉
        TODO: 假设一个URL有64字节(一个url最长是256字节)，如果直接放到内存中进行处理，10亿条url就需要64G的内存，假设内存能放下，
           方法一:我们可以进行排序，相同的url就放到一起了，然后再进行去重。频繁IO,加个缓存一次读取100M;
           方法二:直接通过哈希表进行去重，同样进行hash分片，假设我们有10G内存，64GB每次读取8G数据到内存,8次;md5(url)%8 = 0 ~ 7结果为0的全放内存中去重,
           (排序or哈希表),写到一个小文件中这样，相同的url由于hash得到相同的hash值会加入到同一批文件中然后去重;依次类推，最后把这8个小文件合并即可;


       7.给你a、b两个文件，各自有50亿条URL，每条URL占用64字节，内存限制是4GB，找出a、b文件共同的URL。(10亿字节=1GB,因此如果直接处理需要5*64=320GB
         即a、b两个文件，每个都是320G的数据)
        TODO: (补充知识--字符串大小的比较,不是以字符串的长度直接决定,而是从最左边第一个字符开始比较,大者为大,小者为小,若相等,则继续按字符串顺序比较后面的字符)
          方法一: 先使用分治，多路归并的思想，将a、b两个海量数据进行排序；排序完后使用双指针p,q，对a、b排序之后的数据进行顺序扫描,从a、b中各取出一个url进行比较,
                 相同就放到一个结果文件中,如果不同就看哪个小，然后小的那个指针往后移动;因为a、b已经是排好序的，前面已扫描的url肯定不会和当前的url相同，这样
                 全部数据扫描完后，结果文件里存的就是a、b文件共同的URL。
          方法二: 哈希表，我们使用多机处理，准备200台机器，先到a、b两个文件里，我们只需要各取1.6GB的数据并对其进行hash分片 md5(url)%200 = 0~199 对
                 每一个url计算其hash值，把hash值等于0的URL放到编号0机器的外存里，将hash值等于1的放到编号1的机器里，...........依次类推，
                 直到a、b两个文件里的数据都扫描完毕，此时200个机器里存的都是来自a、b文件里hash值相同的URL了(不同hash值的url肯定是不相同的)，
                 每个机器存的都存有来自a、b的两个小文件，a0、a1、a2、a3、a4、a5...a199；b0、b1、b2、b3、b4、b5...b199；得到这些小文件后，
                 有可能相同的url都在对应的小文件(a0 vs b0,a1 vs b1,...,a199 vs b199)中，不对应的小文件不可能有相同的url。然后我们只要求出
                 200对小文件中相同的url即可。求每对小文件中相同的url时，可以把其中一个小文件的url存储到hash_set中。然后遍历另一个小文件的每个
                 url，看其是否在刚才构建的hash_set中，如果是，那么就是共同的url，存到结果文件里面就可以了，这样不断执行直到100对小文件都处理完毕，
                 此时结果文件里就是a、b文件共同的URL了。

    */


    /**
     * 将byte[]数组转换成16进制字符。一个byte生成两个字符，长度对应1:2
     * @param bytes，输入byte[]数组
     * @return 16进制字符
     */
    public static String byte2Hex(byte[] bytes) {
        if (bytes == null) {
            return null;
        }
        StringBuilder builder = new StringBuilder();
        // 遍历byte[]数组，将每个byte数字转换成16进制字符，再拼接起来成字符串
        for (int i = 0; i < bytes.length; i++) {
            /*
            (符号位中0是表示正，1表示负数)
     TODO:  解释: 0xff，就是16的平方，等于256，相当于8个二进制1，即11111111，之所以使用8个1，是因为byte数组中的每个数字只占1个字节，
            也就是8位，因此要想对其进行位运算，也只能用同样的8位才行,0x100相当于十进制256，也就是二进制的100000000; bytes[i] & 0xff
            这样做是为了防止byte转成int的时候，从8位变成32位，会在高位自动补齐缺少的位数，补齐的数值和byte原来的高位值一样，因为java采用的补码
            的计算方式，当byte为负数的时候，高位补齐的值为1，这样会和原来的值有出入。后面加上0x100的目的是为了始终有2个字符，因为从0~f输出的话，
            就只会有一个字符，加上0x100，这样输出就是3个字符，后面只需要截取后2位即可!具体不理解可以看上面的测试案例
            */
            byte b = bytes[i];
            String binStr = Integer.toBinaryString(b);
            //102二进制是0110 0110，取反得到10011001，再加1得到10011010,也就是-102的二进制表示
            System.out.println("binStr: "+binStr); //输出: 10011010 = 2+8+16+2^7=26+16*8=26+128=154 为何不一样? 因为负数是其正数取反加1
            int num = (bytes[i] & 0xff + 0x100); //10011010 & 11111111 = 10011010 (& 0xff是为了防止转int补齐缺少位数导致数值错误)
            //10011010 + 100000000 = 110011010
            builder.append(Integer.toString(num, 16).substring(1)); //开始正式将十进制数转为16进制
        }
        return builder.toString(); //9a467a5505368da0c81ca19a6b774b6c
    }




}
